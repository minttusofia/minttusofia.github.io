<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Minttu Alakuijala</title>
  
  <meta name="author" content="Minttu Alakuijala">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" type="image/x-icon" href="images/ur5_pick_square.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Minttu Alakuijala</name>
              </p>
              <p>I am a recent PhD graduate from <a href="https://ai.google/research">Google Research</a> (through the CIFRE scheme), <a href="https://www.di.ens.fr/willow/">Inria</a> and <a href="https://www.ens.psl.eu/">Ecole Normale Superieure</a> in Paris. My research has focused on reinforcement learning (RL) and learning from demonstration for robotic manipulation tasks.

              I am currently looking for a <b>postdoctoral or industry research role</b>, with an emphasis on RL and / or language-conditioned tasks.
              </p>
              <p>
                I defended my thesis on <i>Autonomous and Weakly-Supervised Learning for Robotic Manipulation</i> in December 2022. I was advised by <a href="https://www.di.ens.fr/willow/people_webpages/cordelia/">Cordelia Schmid</a>, <a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a> and <a href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:firstname.lastname@gmail.com">Email</a> &nbsp|&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=WmrdmjIAAAAJ">Google Scholar</a> &nbsp|&nbsp
                <a href="https://twitter.com/malakuijala">Twitter</a> &nbsp|&nbsp
                <a href="https://github.com/minttusofia/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/MinttuAlakuijala.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/MinttuAlakuijala_square.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My objective is to advance the scalability and sample-efficiency of RL. Topics of ongoing interest include <b>representation learning, policy priors, multi-task learning, self-supervised RL and learned reward functions</b>. I am particularly motivated by approaches that are applicable across environments and tasks, including but not limited to robotics.

                </p><p>
                As policy state inputs as well as pre-training data, I have worked extensively with image and video modalities; I am also increasingly interested in incorporating language modelling and building language-conditioned interactive agents.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/icra2023_teaser.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2211.09019">
                <papertitle>Learning Reward Functions for Robotic Manipulation by Observing Humans</papertitle>
              </a>
              <br>
              <strong>Minttu Alakuijala</strong>,
              <a href="http://gabe.squirrelsoup.net/">Gabriel Dulac-Arnold</a>,
              <a href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>,
              <a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a>,
              <a href="https://www.di.ens.fr/willow/people_webpages/cordelia/">Cordelia Schmid</a>
              <br>
              <em>ICRA</em>, 2023
              <br>
              <a href="https://sites.google.com/view/hold-rewards">project page</a>
              |
              <a href="https://arxiv.org/abs/2211.09019">arXiv</a>
              <p></p>
              <p>
                We learn dense reward functions for robotic manipulation by learning about distances in state space from videos of humans only, using self-supervised contrastive and regression objectives.
              </p>
            </td>
          </tr>		
		  
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/rrlfd_teaser.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2106.08050">
                <papertitle>Residual Reinforcement Learning from Demonstrations</papertitle>
              </a>
              <br>
              <strong>Minttu Alakuijala</strong>,
              <a href="http://gabe.squirrelsoup.net/">Gabriel Dulac-Arnold</a>,
              <a href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>,
              <a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a>,
              <a href="https://www.di.ens.fr/willow/people_webpages/cordelia/">Cordelia Schmid</a>
              <br>
              <em>RSS 2020 Workshop on Advances & Challenges in Imitation Learning for Robotics</em>
              <br>
              <a href="https://sites.google.com/view/rrlfd">project page</a>
              |
              <a href="https://arxiv.org/abs/2106.08050">arXiv</a>
              <p></p>
              <p>
                Starting from a small number of task demonstrations on a robot arm, we learn an initial base policy and a task-relevant, low-dimensional representation space through behavioral cloning, which is then autonomously improved through residual reinforcement learning using images, proprioceptive inputs and sparse rewards only.
              </p>
            </td>
          </tr>		
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/narrated_actions_teaser.png' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/18FfUR6R2EM5YWhUWiYEO4LcFbzGEz8on/view">
                <papertitle>Discovering Actions by Jointly Clustering Video and Narration Streams Across Tasks</papertitle>
              </a>
              <br>
              <strong>Minttu Alakuijala</strong>,
              <a href="https://lear.inrialpes.fr/people/mairal/">Julien Mairal</a>,
              <a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a>,
              <a href="https://www.di.ens.fr/willow/people_webpages/cordelia/">Cordelia Schmid</a>
              <br>
              <em>CVPR 2020 Workshop on Learning from Instructional Videos</em>
              <br>
              <a href="https://drive.google.com/file/d/18FfUR6R2EM5YWhUWiYEO4LcFbzGEz8on/view">video</a>
              <p></p>
              <p>
                Using only weak supervision from the timing of narration and visual information, we segment narrated tutorial videos into <i>k</i> action classes or background. We use a discriminative clustering objective together with an inconsistency penalty which encourages the timing and order of actions in the visual stream to match that of the narration stream in each video.
              </p>
            </td>
          </tr>		
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a href="https://jonbarron.info/">Jon Barron's website</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
